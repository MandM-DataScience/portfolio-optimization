{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fa48fcb",
   "metadata": {},
   "source": [
    "# Data Cleaning (ETL)\n",
    "**Input**: Raw data stored in MongoDB\n",
    "\n",
    "**Output**: Clean data stored in PostgreSQL\n",
    "\n",
    "The Data Cleaning step consists in multiple data transformations with the goal of making data \"ready to talk\" :)\n",
    "\n",
    "Some of the transformations involved include:\n",
    "- Convert from dictionary to tabular data structure\n",
    "- Remove duplicates (intra-series and inter-series)\n",
    "- Check and convert data types and formats\n",
    "- Null handling\n",
    "- Data interpolation (we have data collected with different frequencies and we want to uniform all data to have monthly frequency)\n",
    "\n",
    "After the step is done, we want to save our transformed data in PostgreSQL, that serves as our Data Warehouse.\n",
    "\n",
    "We evaluated different options to choose where to save our data:\n",
    "- AWS Aurora Serverless / On-demand DB instance\n",
    "- AWS RDS PostgreSQL On-demand DB instance\n",
    "- AWS Redshift\n",
    "\n",
    "Performance-wise redshift would probably be the better choice, it is a columnar database optimized for analytics able to do parallel processing.\n",
    "We could also use Apache Spark for data transformation to improve performance.\n",
    "\n",
    "In this project, as said before, we tried to keep things simple. So we choose PostgreSQL as our data destination and the pandas library as our ETL engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1027dd0d",
   "metadata": {},
   "source": [
    "### FRED Series Selection\n",
    "First thing we export all the ids, titles and notes of the series collected in MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0a2be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\PycharmProjects\\portfolio-optimization\n"
     ]
    }
   ],
   "source": [
    "# move to root to simplify imports\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf1f975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Series: 1810\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NROU</td>\n",
       "      <td>Noncyclical Rate of Unemployment</td>\n",
       "      <td>Starting with the July, 2021 report: An Update...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NROUST</td>\n",
       "      <td>Natural Rate of Unemployment (Short-Term) (DIS...</td>\n",
       "      <td>This series last appeared in the February, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BABANAICSRETSAUS</td>\n",
       "      <td>Business Applications: Retail Trade in the Uni...</td>\n",
       "      <td>The core business applications series that cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BABATOTALSAUS</td>\n",
       "      <td>Business Applications: Total for All NAICS in ...</td>\n",
       "      <td>The core business applications series that cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXPINF10YR</td>\n",
       "      <td>10-Year Expected Inflation</td>\n",
       "      <td>The Federal Reserve Bank of Cleveland estimate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                              title  \\\n",
       "0              NROU                   Noncyclical Rate of Unemployment   \n",
       "1            NROUST  Natural Rate of Unemployment (Short-Term) (DIS...   \n",
       "2  BABANAICSRETSAUS  Business Applications: Retail Trade in the Uni...   \n",
       "3     BABATOTALSAUS  Business Applications: Total for All NAICS in ...   \n",
       "4        EXPINF10YR                         10-Year Expected Inflation   \n",
       "\n",
       "                                               notes  \n",
       "0  Starting with the July, 2021 report: An Update...  \n",
       "1  This series last appeared in the February, 202...  \n",
       "2  The core business applications series that cor...  \n",
       "3  The core business applications series that cor...  \n",
       "4  The Federal Reserve Bank of Cleveland estimate...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "connection_string = f\"mongodb://localhost:27017\"\n",
    "client = MongoClient(connection_string)\n",
    "\n",
    "database = client['portfolio']\n",
    "collection = database['fred_series']\n",
    "datasets = collection.find({})\n",
    "\n",
    "df_l = []\n",
    "\n",
    "for d in datasets:\n",
    "        \n",
    "    _id = d[\"_id\"] if \"_id\" in d else None\n",
    "    title = d[\"title\"] if \"title\" in d else None\n",
    "    notes = d[\"notes\"] if \"notes\" in d else None\n",
    "        \n",
    "    if d[\"popularity\"] >= 30:\n",
    "        df_l.append({\"id\": _id, \"title\": title, \"notes\": notes})\n",
    "\n",
    "df = pd.DataFrame(df_l, columns=[\"id\", \"title\", \"notes\"])\n",
    "\n",
    "print(\"# Series:\", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1a85d5",
   "metadata": {},
   "source": [
    "To shortlist the series available from the FRED we took the following decisions:\n",
    "- Median over Mean\n",
    "- Seasonally Adjusted over Non Seasonally Adjusted\n",
    "- Series taken from OECD excluded\n",
    "- Single state data excluded (we are interested only in federal USA)\n",
    "- Monthly granularity over others\n",
    "- Industry/sector detailed data excluded\n",
    "- DISCONTINUED series excluded\n",
    "- Countries other than USA excluded\n",
    "- Series with data starting after 1995 excluded\n",
    "\n",
    "We then save a list of the \"good\" series in a new document in MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbecffd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Series: 175\n"
     ]
    }
   ],
   "source": [
    "collection = database['fred_datasets']\n",
    "datasets = collection.find({\"_id\":\"shortlist_fred\"}).next()[\"shortlist\"]\n",
    "print(\"# Series:\", len(datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f2241a",
   "metadata": {},
   "source": [
    "### OECD Series Selection\n",
    "As we did for FRED, we export all the different combinations of indicator, measure, subject. In this case the dataset is only one (DP_LIVE), but contains many different combinations for each indicator. We want to shortlist those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbde1363",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Series: 988\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indicator</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agricultural support</td>\n",
       "      <td>Total support (TSE)</td>\n",
       "      <td>% of GDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Agricultural support</td>\n",
       "      <td>Producer support (PSE)</td>\n",
       "      <td>% of gross farm receipts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Crop production</td>\n",
       "      <td>Rice</td>\n",
       "      <td>Tonnes/hectare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Crop production</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>Tonnes/hectare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Gross domestic product (GDP)</td>\n",
       "      <td>Total</td>\n",
       "      <td>Million US dollars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Indicator                 Subject  \\\n",
       "0            Agricultural support     Total support (TSE)   \n",
       "36           Agricultural support  Producer support (PSE)   \n",
       "72                Crop production                    Rice   \n",
       "113               Crop production                   Wheat   \n",
       "154  Gross domestic product (GDP)                   Total   \n",
       "\n",
       "                      Measure  \n",
       "0                    % of GDP  \n",
       "36   % of gross farm receipts  \n",
       "72             Tonnes/hectare  \n",
       "113            Tonnes/hectare  \n",
       "154        Million US dollars  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from configparser import ConfigParser\n",
    "parser = ConfigParser()\n",
    "_ = parser.read(\"credentials.cfg\")\n",
    "username = parser.get(\"mongo_db\", \"username\")\n",
    "password = parser.get(\"mongo_db\", \"password\")\n",
    "\n",
    "connection_string = f\"mongodb+srv://{username}:{password}@cluster0.3dxfmjo.mongodb.net/?\" \\\n",
    "                    f\"retryWrites=true&w=majority\"\n",
    "client = MongoClient(connection_string)\n",
    "\n",
    "database = client['portfolio']\n",
    "oecd_collection = database['oecd_datasets']\n",
    "\n",
    "dataset = oecd_collection.find({\"_id\":\"DP_LIVE\"}).next()\n",
    "\n",
    "def mongo_to_dataframe(dataset):\n",
    "    \n",
    "    data = dataset['dataset']\n",
    "    values = []\n",
    "    obs = data['dataSets'][0]['observations']\n",
    "\n",
    "    for e in obs:\n",
    "        i = [int(x) for x in e.split(\":\")]\n",
    "        i.append(obs[e][0])\n",
    "        values.append(i)\n",
    "\n",
    "    obs_cols = data['structure']['dimensions']['observation']\n",
    "    replacement = {}\n",
    "    cols = []\n",
    "    for c in obs_cols:\n",
    "        n = c[\"name\"]\n",
    "        replacement[n] = {i: x[\"name\"] for i, x in enumerate(c['values'])}\n",
    "        cols.append(n)\n",
    "\n",
    "    df = pd.DataFrame(values, columns=cols + [\"Value\"])\n",
    "    for c in cols:\n",
    "        df[c] = df[c].replace(replacement[c])\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = mongo_to_dataframe(dataset)\n",
    "df = df[[\"Indicator\",\"Subject\",\"Measure\"]].drop_duplicates()\n",
    "\n",
    "print(\"# Series:\", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c414b",
   "metadata": {},
   "source": [
    "To shortlist the series available from the OECD we took the following decisions:\n",
    "- General \"Subject\" over segmented \"Subject\" (ex. Total over Male/Female, Financial/Non-financial)\n",
    "- Industry/sector detailed data excluded\n",
    "- Series with data starting after 1995 excluded\n",
    "\n",
    "We then save a list of the \"good\" series in a new document in MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e99cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Series: 106\n"
     ]
    }
   ],
   "source": [
    "datasets = oecd_collection.find({\"_id\":\"oecd_shortlist\"}).next()[\"data\"]\n",
    "print(\"# Series:\", len(datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72656c36",
   "metadata": {},
   "source": [
    "### FRED + OECD Series union\n",
    "At this point we \"merge\" the features coming from the FRED and the OECD and remove the duplicate ones.\n",
    "\n",
    "When in doubt we keep the one that has more data or the one with the lowest granularity (eg. monthly over quarterly).\n",
    "\n",
    "We save the new shortlisted list of series in 2 documents name fred_shortlist_v2 and oecd_shortlist_v2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24931103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Series FRED: 142\n",
      "# Series OECD: 67\n"
     ]
    }
   ],
   "source": [
    "fred_collection = database['fred_datasets']\n",
    "fred_shortlist = fred_collection.find({\"_id\":\"shortlist_fred_v2\"}).next()[\"shortlist\"]\n",
    "print(\"# Series FRED:\", len(fred_shortlist))\n",
    "\n",
    "oecd_shortlist = oecd_collection.find({\"_id\":\"oecd_shortlist_v2\"}).next()[\"data\"]\n",
    "print(\"# Series OECD:\", len(oecd_shortlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9eea22",
   "metadata": {},
   "source": [
    "## ETL\n",
    "Now we are ready for the ETL process (Extract, Transform, Load)\n",
    "- Extract (selected) data from MongoDB, that contains our raw data\n",
    "- Transform data using pandas\n",
    "- Load into postgreSQL\n",
    "\n",
    "### FRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18e45f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features 123\n",
      "# rows: 80441\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>name</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0.321</td>\n",
       "      <td>WFRBST01134</td>\n",
       "      <td>FRED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>0.322</td>\n",
       "      <td>WFRBST01134</td>\n",
       "      <td>FRED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>0.322</td>\n",
       "      <td>WFRBST01134</td>\n",
       "      <td>FRED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>0.322</td>\n",
       "      <td>WFRBST01134</td>\n",
       "      <td>FRED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.319</td>\n",
       "      <td>WFRBST01134</td>\n",
       "      <td>FRED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  value         name source\n",
       "386 2021-09-01  0.321  WFRBST01134   FRED\n",
       "387 2021-10-01  0.322  WFRBST01134   FRED\n",
       "388 2021-11-01  0.322  WFRBST01134   FRED\n",
       "389 2021-12-01  0.322  WFRBST01134   FRED\n",
       "390 2022-01-01  0.319  WFRBST01134   FRED"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "fred_documents = fred_collection.find({\"_id\":{\"$in\": fred_shortlist}})\n",
    "fred_api_key = parser.get(\"fred\", \"fred_api_key\")\n",
    "\n",
    "def retrieve_series_metadata(series_id, api_key):\n",
    "    url = f\"https://api.stlouisfed.org/fred/series?series_id={series_id}\" \\\n",
    "            f\"&api_key={api_key}&file_type=json\"\n",
    "    \n",
    "    from portfolio_optimization.data_collection import request_with_retries\n",
    "    \n",
    "    r = request_with_retries(url)\n",
    "    return r.json()['seriess'][0]\n",
    "\n",
    "# We create a transformed Dataframe for each document and then concat them together\n",
    "list_of_dfs = []\n",
    "\n",
    "for d in fred_documents:\n",
    "\n",
    "    # Retrieve Metadata (Unit of measure and frequency)\n",
    "    try:\n",
    "        metadata = retrieve_series_metadata(d[\"_id\"], fred_api_key)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    units = metadata[\"units\"]\n",
    "    frequency = metadata[\"frequency\"]\n",
    "    \n",
    "    # Build Dataframe\n",
    "    tmp = []\n",
    "    for o in d[\"observations\"]:\n",
    "        tmp.append({key: o[key] for key in [\"date\",\"value\"]})\n",
    "    df = pd.DataFrame(tmp, columns=[\"date\",\"value\"])\n",
    "    \n",
    "    # Convert Types\n",
    "    df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "                  \n",
    "    # Adjust % values\n",
    "    if units is not None and \"Percent\" in units:\n",
    "        df[\"value\"] /= 100\n",
    "    \n",
    "    # Interpolate values\n",
    "    # Starting from weekly frequency we take the mean to get the monthly value\n",
    "    # Starting from higher granularity we use ffill to \"copy\" the value in the missing months.\n",
    "    # We use this method instead of linear interpolation because Quarterly and Annual data is \n",
    "    # already made up from the average of the monthly observations! This is a way to keep at \n",
    "    # least the same average before and after the transformation\n",
    "    if \"Weekly\" in frequency:\n",
    "        df = df.set_index([\"date\"]).resample('MS').mean().reset_index()\n",
    "    if \"Quarterly\" in frequency or \"Annual\" in frequency:\n",
    "        df = df.set_index([\"date\"]).resample('MS').ffill().reset_index()\n",
    "    \n",
    "    # Remove rows with any null present\n",
    "    df = df.dropna()\n",
    "    df[\"name\"] = d[\"_id\"]\n",
    "                  \n",
    "    list_of_dfs.append(df)\n",
    "\n",
    "df = pd.concat(list_of_dfs)\n",
    "df[\"source\"] = \"FRED\"\n",
    "print(\"# features\", len(df[\"name\"].unique()))\n",
    "print(\"# rows:\", len(df))\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed20abaf",
   "metadata": {},
   "source": [
    "### OECD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ef352dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features 67\n",
      "# rows: 42125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>name</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42120</th>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>120.8771</td>\n",
       "      <td>Unit labour costs | By persons employed | 2015...</td>\n",
       "      <td>OECD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42121</th>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>122.7363</td>\n",
       "      <td>Unit labour costs | By persons employed | 2015...</td>\n",
       "      <td>OECD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42122</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>122.7363</td>\n",
       "      <td>Unit labour costs | By persons employed | 2015...</td>\n",
       "      <td>OECD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42123</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>122.7363</td>\n",
       "      <td>Unit labour costs | By persons employed | 2015...</td>\n",
       "      <td>OECD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42124</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>123.7721</td>\n",
       "      <td>Unit labour costs | By persons employed | 2015...</td>\n",
       "      <td>OECD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     value                                               name  \\\n",
       "42120 2022-06-01  120.8771  Unit labour costs | By persons employed | 2015...   \n",
       "42121 2022-07-01  122.7363  Unit labour costs | By persons employed | 2015...   \n",
       "42122 2022-08-01  122.7363  Unit labour costs | By persons employed | 2015...   \n",
       "42123 2022-09-01  122.7363  Unit labour costs | By persons employed | 2015...   \n",
       "42124 2022-10-01  123.7721  Unit labour costs | By persons employed | 2015...   \n",
       "\n",
       "      source  \n",
       "42120   OECD  \n",
       "42121   OECD  \n",
       "42122   OECD  \n",
       "42123   OECD  \n",
       "42124   OECD  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = oecd_collection.find({'_id':\"DP_LIVE\"}).next()\n",
    "df = mongo_to_dataframe(dataset)\n",
    "\n",
    "# Transform date\n",
    "# monthly data has format 'YYYY-MM-DD' and is already fine\n",
    "# quarterly data has format 'YYYY-Q1' and must be transformed\n",
    "# yearly data has format 'YYYY' and must be transformed\n",
    "from portfolio_optimization.helper import oecd_time_to_datetime\n",
    "df[\"Time\"] = df.apply(lambda row: oecd_time_to_datetime(row, \"Time\"), axis=1)\n",
    "\n",
    "# We create a transformed Dataframe for each combination of indicator,subject,measure\n",
    "# and then concat them together\n",
    "list_of_dfs = []\n",
    "\n",
    "for s in oecd_shortlist:\n",
    "    \n",
    "    # Take only shortlisted combination of indicator,subject,measure\n",
    "    temp_df = df[(df[\"Indicator\"] == s[\"INDICATOR\"]) & \n",
    "                 (df[\"Subject\"] == s[\"SUBJECT\"]) & \n",
    "                 (df[\"Measure\"] == s[\"MEASURE\"])]\n",
    "    \n",
    "    # Interpolate values\n",
    "    # Each combination can have one or multiple different frequencies.\n",
    "    # If we have the monthly frequency, we just take that\n",
    "    # If we don't, we use the same strategy as for FRED, we use ffill to \"copy\" the value\n",
    "    frequencies = temp_df[\"Frequency\"].unique()\n",
    "    if \"Monthly\" in frequencies:\n",
    "        temp_df = temp_df[temp_df[\"Frequency\"] == \"Monthly\"]\n",
    "    elif \"Quarterly\" in frequencies:\n",
    "        temp_df = temp_df[temp_df[\"Frequency\"] == \"Quarterly\"]\n",
    "        temp_df = temp_df.set_index([\"Time\"]).resample('MS').ffill().reset_index()\n",
    "    elif \"Annual\" in frequencies:\n",
    "        temp_df = temp_df[temp_df[\"Frequency\"] == \"Annual\"]\n",
    "        temp_df = temp_df.set_index([\"Time\"]).resample('MS').ffill().reset_index()\n",
    "        \n",
    "    list_of_dfs.append(temp_df)\n",
    "\n",
    "df = pd.concat(list_of_dfs)\n",
    "df = df.dropna()\n",
    "\n",
    "# Adjust % values\n",
    "def convert_percentage(row):\n",
    "    for el in [\"%\", \"percentage\"]:\n",
    "        if el in row[\"Measure\"].lower():\n",
    "            return row[\"Value\"] / 100\n",
    "    return row[\"Value\"]\n",
    "\n",
    "df[\"Value\"] = df.apply(lambda row: convert_percentage(row), axis=1)\n",
    "\n",
    "# Concat combination into a single column\n",
    "def concat_column_values(row, columns):\n",
    "    return ' | '.join(list(row[columns]))\n",
    "\n",
    "df['name'] = df.apply(lambda row: concat_column_values(row, [\"Indicator\", \"Subject\", \"Measure\"]), \n",
    "                      axis=1)\n",
    "\n",
    "# Drop useless columns\n",
    "df = df.drop([\"Indicator\", \"Subject\", \"Measure\", \"Country\", \"Frequency\"], axis=1)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df['source'] = 'OECD'\n",
    "df = df.rename(columns={\"Time\": \"date\", \"Value\":\"value\"})\n",
    "df = df[[\"date\", \"value\", \"name\", \"source\"]]\n",
    "\n",
    "print(\"# features\", len(df[\"name\"].unique()))\n",
    "print(\"# rows:\", len(df))\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a8296b",
   "metadata": {},
   "source": [
    "### YahooFinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31e11d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# targets 11\n",
      "# rows: 2878\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>^TNX</td>\n",
       "      <td>yahoo_finance</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>3.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>^TNX</td>\n",
       "      <td>yahoo_finance</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>3.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>^TNX</td>\n",
       "      <td>yahoo_finance</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>3.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>^TNX</td>\n",
       "      <td>yahoo_finance</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>3.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>^TNX</td>\n",
       "      <td>yahoo_finance</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name         source       date  value\n",
       "2873  ^TNX  yahoo_finance 2022-12-01  3.879\n",
       "2874  ^TNX  yahoo_finance 2023-01-01  3.529\n",
       "2875  ^TNX  yahoo_finance 2023-02-01  3.916\n",
       "2876  ^TNX  yahoo_finance 2023-03-01  3.494\n",
       "2877  ^TNX  yahoo_finance 2023-04-01  3.413"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take data from MongoDB\n",
    "yf_collection = database['yf_target_datasets']\n",
    "yf_datasets = yf_collection.find({})\n",
    "\n",
    "# Build Dataframe\n",
    "list_of_df = []\n",
    "\n",
    "for d in yf_datasets:\n",
    "    tmp = []\n",
    "    for dd in d[\"data\"]:\n",
    "        tmp.append({\"date\":dd[\"Date\"], \"value\":dd[\"Close\"], \"name\":dd[\"ticker\"]})\n",
    "    list_of_df.append(pd.DataFrame(tmp, columns=[\"date\",\"value\",\"name\"]))\n",
    "\n",
    "df = pd.concat(list_of_df)\n",
    "\n",
    "# Convert Types\n",
    "df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"],unit='ms')\n",
    "\n",
    "# Drop nulls\n",
    "df = df.dropna()\n",
    "\n",
    "df[\"source\"] = \"yahoo_finance\"\n",
    "df = df[[\"date\", \"value\", \"name\", \"source\"]]\n",
    "\n",
    "# For the most recent month we get 2 values, 1 for the start of month, 1 for today's date.\n",
    "# We just want the start of month\n",
    "df = df.set_index([\"date\"]).groupby([\"name\",\"source\"]).resample('MS')\\\n",
    "    .mean().reset_index()\n",
    "\n",
    "\n",
    "print(\"# targets\", len(df[\"name\"].unique()))\n",
    "print(\"# rows:\", len(df))\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d4f476",
   "metadata": {},
   "source": [
    "### Investing.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ffa303f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# targets 3\n",
      "# rows: 1516\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>WHEAT</td>\n",
       "      <td>investing</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>795.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>WHEAT</td>\n",
       "      <td>investing</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>792.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>WHEAT</td>\n",
       "      <td>investing</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>761.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>WHEAT</td>\n",
       "      <td>investing</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>705.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>WHEAT</td>\n",
       "      <td>investing</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>686.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name     source       date   value\n",
       "1511  WHEAT  investing 2022-11-01  795.50\n",
       "1512  WHEAT  investing 2022-12-01  792.00\n",
       "1513  WHEAT  investing 2023-01-01  761.25\n",
       "1514  WHEAT  investing 2023-02-01  705.50\n",
       "1515  WHEAT  investing 2023-03-01  686.40"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take data from MongoDB\n",
    "investing_collection = database['investing_target_datasets']\n",
    "investing_datasets = investing_collection.find({})\n",
    "\n",
    "# Build Dataframe\n",
    "list_of_df = []\n",
    "\n",
    "for d in investing_datasets:\n",
    "    \n",
    "    name = d[\"_id\"]\n",
    "    tmp = []\n",
    "    for dd in d[\"data\"]:\n",
    "        tmp.append({\"date\":dd[\"Date\"], \"value\":dd[\"Price\"], \"name\":name})\n",
    "\n",
    "    list_of_df.append(pd.DataFrame(tmp, columns=[\"date\",\"value\",\"name\"]))\n",
    "\n",
    "df = pd.concat(list_of_df)\n",
    "\n",
    "# Convert Types\n",
    "df[\"value\"] = df[\"value\"].astype(str)\n",
    "df[\"value\"] = pd.to_numeric(df[\"value\"].str.replace(\",\",\"\"), errors=\"coerce\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# Drop nulls\n",
    "df = df.dropna()\n",
    "\n",
    "df[\"source\"] = \"investing\"\n",
    "df = df[[\"date\", \"value\", \"name\", \"source\"]]\n",
    "\n",
    "# For the most recent month we get 2 values, 1 for the start of month, 1 for today's date.\n",
    "# We just want the start of month\n",
    "df = df.set_index([\"date\"]).groupby([\"name\",\"source\"]).resample('MS')\\\n",
    "    .mean().reset_index()\n",
    "\n",
    "print(\"# targets\", len(df[\"name\"].unique()))\n",
    "print(\"# rows:\", len(df))\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe7422c",
   "metadata": {},
   "source": [
    "### Storing Data in PostgreSQL\n",
    "We save transformed data in PostgreSQL on AWS RDS, which we use as a Data Warehouse.\n",
    "\n",
    "https://aws.amazon.com/rds/postgresql/\n",
    "\n",
    "To store a pandas Dataframe we use psycopg2 library.\n",
    "\n",
    "Below an example of how to connect to PostgreSQL and insert a Dataframe into a specific table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8bc7616",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_USER = parser.get(\"postgresql\", \"DB_USER\")\n",
    "DB_PASS = parser.get(\"postgresql\", \"DB_PASS\")\n",
    "DB_HOST = parser.get(\"postgresql\", \"DB_HOST\")\n",
    "DB_NAME = parser.get(\"postgresql\", \"DB_NAME\")\n",
    "DB_PORT = parser.get(\"postgresql\", \"DB_PORT\")\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2 import extras\n",
    "\n",
    "def insert_df_into_table(df, tablename):\n",
    "    # PostgreSQL does not like nan\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    cols = ','.join(list(df.columns))\n",
    "\n",
    "    query = \"INSERT INTO %s(%s) VALUES %%s ON CONFLICT DO NOTHING;\" % (tablename, cols)\n",
    "\n",
    "    # This calls psycopg2.connect passing connection parameters\n",
    "    conn = get_connection()\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        traceback.print_exc()\n",
    "        eprint(f\"Error: {error}\")\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "    finally:\n",
    "        cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0382e5d6",
   "metadata": {},
   "source": [
    "At this point we have our transformed data stored in PostgreSQL and we can start analysing it.\n",
    "\n",
    "Let's continue on the next step EDA (Exploratory data analysis).\n",
    "\n",
    "[Go to EDA](eda.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "finance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

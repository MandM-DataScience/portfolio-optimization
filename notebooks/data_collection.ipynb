{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio optimization\n",
    "**Problem**: Is it possible to use macroeconomic data to \"predict\" an optimal asset allocation for a portfolio to achieve better risk-adjusted returns?\n",
    "\n",
    "## Data Collection\n",
    "**Input**: -\n",
    "\n",
    "**Output**: Raw data stored in MongoDB\n",
    "\n",
    "Where we took data from:\n",
    "- OECD (https://data.oecd.org/api/)\n",
    "- FRED (https://fred.stlouisfed.org/docs/api/fred/)\n",
    "- YahooFinance (library yfinance)\n",
    "- Investing.com (scraping with BeautifulSoup4)\n",
    "\n",
    "First thing, we choose what indexes to use as a benchmark for the different asset classes (Equity, Bond, Real Estate, Commodity, Cash). These will be the **targets** in our model.\n",
    "\n",
    "Equity (Yahoo finance, with related ticker):\n",
    "- SP500 ^GSPC\n",
    "- DowJones ^DJI\n",
    "- Nasdaq ^IXIC\n",
    "- Russell2000 ^RUT\n",
    "\n",
    "Bond:\n",
    "- Long-term interest rates (OECD https://data.oecd.org/interest/long-term-interest-rates.htm)\n",
    "- Treasury10Y Yield (Yahoo Finance ^TNX) \n",
    "\n",
    "Real Estate:\n",
    "- All-Transactions House Price Index (FRED series_id = USSTHPI)\n",
    "- Housing prices (OECD https://data.oecd.org/price/housing-prices.htm)\n",
    "\n",
    "Commodity (Investing.com):\n",
    "- GOLD (https://www.investing.com/commodities/gold)\n",
    "- OIL (https://www.investing.com/commodities/crude-oil)\n",
    "- WHEAT (https://www.investing.com/commodities/us-wheat)\n",
    "\n",
    "Cash (OECD):\n",
    "- Short-term interest rates (OECD https://data.oecd.org/interest/short-term-interest-rates.htm)\n",
    "\n",
    "As **features** we take every series in the FRED and OECD datasets. These contain data such as gdp, growth, inflation, unemployment, equity market volatility, new houses permits, FED rates, gold reserves, balance of payments, and much more.\n",
    "\n",
    "We save raw data as-is in MongoDB Atlas, which we use as a Data Lake.\n",
    "The alternatives we evaluated are S3 and DocumentDB (AWS).\n",
    "We choose MongoDB Atlas, as it allows a Free Tier with 512MB of storage, while also allowing to query the documents (unlike S3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OECD Data Collection\n",
    "OECD presents data via REST API with no auth.\n",
    "\n",
    "https://data.oecd.org/api/sdmx-json-documentation/\n",
    "\n",
    "Data can be retrieved via http requests containing filters and dataset id.\n",
    "\"Live\" most recent data is in the DP_LIVE dataset.\n",
    "\n",
    "Here we get all features data from OECD + 3 targets described above.\n",
    "\n",
    "Below an example of a request for GDP data for USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\PycharmProjects\\portfolio-optimization\n"
     ]
    }
   ],
   "source": [
    "# move to root to simplify imports\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'action': 'Information', 'observations': {'0:0:0:0:0:0': [15048970.0, 0, None], '0:0:0:0:0:1': [15599731.0, 0, None], '0:0:0:0:0:2': [16253970.0, 0, None], '0:0:0:0:0:3': [16843196.0, 0, None], '0:0:0:0:0:4': [17550687.0, 0, None], '0:0:0:0:0:5': [18206023.0, 0, None], '0:0:0:0:0:6': [18695106.0, 0, None], '0:0:0:0:0:7': [19477337.0, 0, None], '0:0:0:0:0:8': [20533058.0, 0, None], '0:0:0:0:0:9': [21380976.0, 0, None], '0:0:0:0:0:10': [21060474.0, 0, None], '0:0:0:0:0:11': [23315081.0, 0, None]}}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = f'https://stats.oecd.org/SDMX-JSON/data/DP_LIVE/USA.GDP..MLN_USD./all?dimensionAtObservation=allDimensions&startTime=2010'\n",
    "r = requests.get(url).json()\n",
    "print(r[\"dataSets\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data format is a little bit oscure at this point, but we will solve (and explain) this in the Data cleaning part of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FRED Data collection\n",
    "FRED presents data via REST API with authentication via api_key (free to request and use)\n",
    "https://fred.stlouisfed.org/docs/api/fred/\n",
    "\n",
    "To retrieve a series data you need to specify the corresponding series_id.\n",
    "We couldn't find a comprehensive series_id list, so we decided to traverse the whole tree structure of categories and series.\n",
    "We started from the root category and ask for the category children and so on. When we have all the categories we ask for the series contained in that category. This way we retrieved all possible series_id.\n",
    "\n",
    "Due to a higher than excepted amount of data, we chose to keep only series with \"popularity\" >= 30. Popularity is a metadata of each series representing interest of public in that series data. (For example \"GDP\" data for USA is \"more interesting\" than \"Employed Persons in Talbot County, GA\" data)\n",
    "\n",
    "Here we get all features data from FRED + 1 target described above.\n",
    "\n",
    "Below an example of a request for GDP data for USA. api_key is been obscured for privacy reasons, to run the same you will need to request an api_key from FRED.\n",
    "\n",
    "https://fred.stlouisfed.org/docs/api/api_key.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-10-01</th>\n",
       "      <td>24349.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>24740.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01</th>\n",
       "      <td>25248.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-01</th>\n",
       "      <td>25723.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-01</th>\n",
       "      <td>26137.992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "2021-10-01  24349.121\n",
       "2022-01-01  24740.480\n",
       "2022-04-01  25248.476\n",
       "2022-07-01  25723.941\n",
       "2022-10-01  26137.992"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fredapi as fa\n",
    "import os\n",
    "from configparser import ConfigParser\n",
    "\n",
    "parser = ConfigParser()\n",
    "_ = parser.read(\"credentials.cfg\")\n",
    "fred_api_key = parser.get(\"fred\", \"fred_api_key\")\n",
    "\n",
    "fred = fa.Fred(api_key=fred_api_key)\n",
    "df = fred.get_series(\"GDP\").to_frame()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YahooFinance Data Collection\n",
    "For YahooFinance data we can use the yfinance library.\n",
    "\n",
    "https://pypi.org/project/yfinance/\n",
    "\n",
    "Here we get the target data we need from YahooFinance as described above.\n",
    "\n",
    "Below an example of a request for S&P500 price data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>3853.290039</td>\n",
       "      <td>4094.209961</td>\n",
       "      <td>3794.330078</td>\n",
       "      <td>4076.600098</td>\n",
       "      <td>80763810000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-01</th>\n",
       "      <td>4070.070068</td>\n",
       "      <td>4195.439941</td>\n",
       "      <td>3943.080078</td>\n",
       "      <td>3970.149902</td>\n",
       "      <td>80392280000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01</th>\n",
       "      <td>3963.340088</td>\n",
       "      <td>4110.750000</td>\n",
       "      <td>3808.860107</td>\n",
       "      <td>4109.310059</td>\n",
       "      <td>113094800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01</th>\n",
       "      <td>4102.200195</td>\n",
       "      <td>4133.129883</td>\n",
       "      <td>4069.840088</td>\n",
       "      <td>4109.109863</td>\n",
       "      <td>19340860000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-11</th>\n",
       "      <td>4110.290039</td>\n",
       "      <td>4115.359863</td>\n",
       "      <td>4102.890137</td>\n",
       "      <td>4102.910156</td>\n",
       "      <td>465928982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close        Volume  \\\n",
       "Date                                                                           \n",
       "2023-01-01  3853.290039  4094.209961  3794.330078  4076.600098   80763810000   \n",
       "2023-02-01  4070.070068  4195.439941  3943.080078  3970.149902   80392280000   \n",
       "2023-03-01  3963.340088  4110.750000  3808.860107  4109.310059  113094800000   \n",
       "2023-04-01  4102.200195  4133.129883  4069.840088  4109.109863   19340860000   \n",
       "2023-04-11  4110.290039  4115.359863  4102.890137  4102.910156     465928982   \n",
       "\n",
       "            Dividends  Stock Splits  \n",
       "Date                                 \n",
       "2023-01-01          0             0  \n",
       "2023-02-01          0             0  \n",
       "2023-03-01          0             0  \n",
       "2023-04-01          0             0  \n",
       "2023-04-11          0             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "ticker = \"^GSPC\"\n",
    "t = yf.Ticker(ticker)\n",
    "df = t.history(period=\"max\", interval=\"1mo\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investing.com Data Collection\n",
    "For investing.com we manually download data in .csv and created a scraper that retrieve subsequential data.\n",
    "\n",
    "The problem with the scraper is that data after the past month is loaded via javascript in the webpage.\n",
    "\n",
    "It could possibly be achieved using Selenium, but we tried to keep things as simple as possible using only BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing Data in MongoDB\n",
    "We save raw data as-is in MongoDB Atlas, which we use as a Data Lake.\n",
    "\n",
    "https://www.mongodb.com/cloud/atlas/register\n",
    "\n",
    "To store a pandas Dataframe we have to convert it to a dictionary.\n",
    "\n",
    "Each document in MongoDB is assigned a random \"_id\". We can override this to achieve an unique column in the collection.\n",
    "\n",
    "Below an example of how to connect to MongoDB (in this case Atlas version) and insert a json file into a desired database and collection. You would need an account on MongoDB Atlas to run this. Or alternatively you can install MongoDB on your local machine and the connection string would look like: *\"mongodb://localhost:27017\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import json\n",
    "\n",
    "from configparser import ConfigParser\n",
    "parser = ConfigParser()\n",
    "_ = parser.read(\"credentials.cfg\")\n",
    "username = parser.get(\"mongo_db\", \"username\")\n",
    "password = parser.get(\"mongo_db\", \"password\")\n",
    "\n",
    "data = {\"_id\":ticker, \"data\":json.loads(df.reset_index().to_json(orient=\"records\"))}\n",
    "\n",
    "connection_string = f\"mongodb+srv://{username}:{password}@cluster0.3dxfmjo.mongodb.net/?\" \\\n",
    "                    f\"retryWrites=true&w=majority\"\n",
    "client = MongoClient(connection_string)\n",
    "\n",
    "# database = client[db_name]\n",
    "# collection = database[collection]\n",
    "# collection.insert_one(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have all raw data stored in MongoDB and we are ready to continue into the next phase, that is wrangling data to be prepared to be analyzed.\n",
    "\n",
    "The transformed data will be saved in PostgreSQL.\n",
    "\n",
    "[Go to Data Cleaning](data_cleaning.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio_optimization",
   "language": "python",
   "name": "portfolio_optimization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
